<h1 class="code-line" data-line-start=0 data-line-end=1 ><a id="Hassan_Ali_0"></a>Hassan Ali</h1>

<p class="has-line-data" data-line-start="2" data-line-end="4">
<a href=mailto:“hassanalikhatim@gmail.com”>Mail</a> | 
<a href="https://hassanalikhatim.github.io/documents/Resume.pdf", target="_blank">CV</a> | 
<a href="https://scholar.google.com/citations?user=MhiaZiQAAAAJ&hl=en">Google Scholar</a> | 
<a href="https://github.com/hassanalikhatim">Github</a> | 
<a href="https://hassanalikhatim.github.io/pages/publications.html">Publications and Preprints</a>
</p>
<p class="has-line-data" data-line-start="5" data-line-end="6">
I work as a Research Assistant at IHSAN Lab, Information Technology University (ITU), Lahore, Pakistan.

<br><br>My research interests are diverse.
<br>&emsp; &bull; &emsp; I want to build frameworks for reliable and trustworthy Artificial Intelligence (AI) algorithms focused on real-world applications and challenges.
<br>&emsp; &bull; &emsp; I am interested in few-shot media generation, particularly text-to-video generation, using AI.
<br>&emsp; &bull; &emsp; I want to enable ML as a product in real-world settings (e.g., ML as a service (supporting encryption standards/protocols), ML on edge).

<br><br>My past research work has largely focused on the trustworthy Machine Learning (ML) algorithms, particularly Deep Neural Networks (DNNs), where the trustworthiness refers to the adversarial robustness, security, privacy, interpretability, alignment and fairness of DNNs.

<br><br>I can be contacted at: <a href=mailto:“hassanalikhatim@gmail.com”>hassanalikhatim@gmail.com</a>
</p>

<h2></a>News</h2>
<ul >

<li>
<u>Aug 2023</u>: 
Our paper "Secure and Trustworthy Artificial Intelligence-Extended Reality (AI-XR) for Metaverses" has been accepted at ACM Computing Surveys.<br>
</li>

<li>
<u>Jul 2023</u>: 
Our paper "ConDetect: Detecting Adversarially Perturbed Natural Language Inputs to Deep Classifiers Through Holistic Analysis" has been accepted at Computers & Security.<br>
</li>

<li>
<u>Dec 2022</u>: 
Our paper "Towards secure private and trustworthy human-centric embedded machine learning: An emotion-aware facial recognition case study" has been accepted at Computers & Security.<br>
</li>

<li>
<u>Jun 2022</u>: 
Our paper "Tamp-X: Attacking Explainable Natural Language Classifiers Through Tampered Activations" has been accepted at Computers & Secruity.<br>
</li>

</ul>

<h2></a>Selected Works</h2>
<ol >

<li>
<b>Membership Inference Attacks on DNNs using Adversarial Perturbations</b><br><u>Hassan Ali</u>, Adnan Qayyum, Ala Al-Fuqaha, and Junaid Qadir <br><em>arXiv preprint arXiv:2307.05193 (2023)</em>. <br>Links: [<a href="https://arxiv.org/pdf/2307.05193">Paper</a>]
[<a href="https://github.com/hassanalikhatim/AMIA">Code</a>]
<br>

</li>

<li>
<b>Consistent Valid Physically-Realizable Adversarial Attack against Crowd-flow Prediction Models</b><br><u>Hassan Ali</u>, Muhammad Atif Butt, Fethi Filali, Ala Al-Fuqaha, and Junaid Qadir <br><em>arXiv preprint arXiv:2303.02669 (2023)</em>. <br>Links: [<a href="https://arxiv.org/pdf/2303.02669">Paper</a>]
[<a href="https://github.com/hassanalikhatim/CVP-Attack">Code</a>]
<br>

</li>

<li>
<b>Con-detect: Detecting adversarially perturbed natural language inputs to deep classifiers through holistic analysis</b><br><u>Hassan Ali</u>*, Muhammad Suleman Khan*, Amer AlGhadhban, Meshari Alazmi, Ahmad Alzamil, Khaled AlUtaibi, and Junaid Qadir (*equal contribution)<br><em>Computers & Security 132 (2023): 103367</em>. <br>Links: [<a href="https://www.sciencedirect.com/science/article/pii/S0167404823002778">Paper</a>]
[<a href="https://github.com/hassanalikhatim/Con-Detect">Code</a>]
<br>

</li>

<li>
<b>Tamp-X: Attacking explainable natural language classifiers through tampered activations</b><br><u>Hassan Ali</u>*, Muhammad Suleman Khan*, Ala Al-Fuqaha, and Junaid Qadir (*equal contribution)<br><em>Computers & Security 120 (2022): 102791</em>. <br>Links: [<a href="https://www.sciencedirect.com/science/article/pii/S0167404822001857">Paper</a>]
[<a href="https://github.com/hassanalikhatim/Tamp-X">Code</a>]
<br>

</li>

<li>
<b>Fadec: A fast decision-based attack for adversarial machine learning</b><br>Faiq Khalid*, <u>Hassan Ali</u>*, Muhammad Abdullah Hanif, Semeen Rehman, Rehan Ahmed, and Muhammad Shafique (*equal contribution)<br><em>In 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. IEEE, 2020</em>. <br>Links: [<a href="https://ieeexplore.ieee.org/abstract/document/9207635/">Paper</a>]
[<a href="https://github.com/hassanalikhatim/QuSecNets_SSCNets_FaDec">Code</a>]
<br>

</li>

</ol>

